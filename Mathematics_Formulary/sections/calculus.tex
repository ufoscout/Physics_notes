\chapter{Calculus}
\textbf{Definition:} Calculus (from Latin calculus, literally 'small pebble', used for counting and calculations, as on an abacus) is the mathematical study of continuous change. It has two major branches:
\begin{itemize}  
	\item \textbf{differential calculus:} concerning rates of change and slopes of curves;
	\item \textbf{integral calculus:} concerning accumulation of quantities and the areas under and between curves
\end{itemize}
These two branches are related to each other by the fundamental theorem of calculus. 


\section{Limits}

$ \displaystyle \lim_{x\rightarrow\pm\infty}P(x)=\lim_{x\rightarrow\pm\infty}a_nx^x=\pm\infty $

$ \displaystyle \lim_{x\rightarrow\pm\infty}\frac{P(x)}{Q(x)}=\lim_{x\rightarrow\pm\infty}\frac{a_nx^x}{b_mx^m}=\lim_{x\rightarrow\pm\infty}\frac{a_n}{b_m}x^{n-m}=
\begin{cases}
\infty & \text{if } n>m \\
\frac{a_n}{b_m} & \text{if } n=m \\
0 & \text{if } n<m \\
\end{cases} $

$ \displaystyle
\lim_{x\rightarrow0}\frac{\sin(x)}{x}=1 ~~,~~ \lim_{x\rightarrow0}\frac{1-\cos(x)}{x^2}=\frac{1}{2}
$

$ \displaystyle
\lim_{x\rightarrow0}\frac{\tan(x)}{x}=1 ~~,~~ \lim_{x\rightarrow0}\frac{\arcsin(x)}{x}=1
$

$ \displaystyle
\lim_{x\rightarrow0}\frac{\log_a(x+1)}{x}=\frac{1}{\ln(a)} ~~ (a>0) ~~,~~
\lim_{x\rightarrow0}\frac{\ln(x+a)}{x}=a
$

$ \displaystyle
\lim_{x\rightarrow+\infty}x^\alpha=+\infty ~~,~~ \lim_{x\rightarrow0^+}x^\alpha=0 ~~~~ \alpha>0
$

$ \displaystyle
\lim_{x\rightarrow+\infty}x^\alpha=0 ~~,~~ \lim_{x\rightarrow0^+}x^\alpha=+\infty ~~~~ \alpha<0
$

$ \displaystyle
\lim_{x\rightarrow0}\frac{a^x-1}{x}=ln(a) ~~,~~ \lim_{x\rightarrow0}\frac{e^x-1}{x}=1
$

$ \displaystyle
\lim_{x\rightarrow+\infty}a^x=+\infty ~~,~~ \lim_{x\rightarrow-\infty}a^x=0 ~~~~ a>1
$

$ \displaystyle
\lim_{x\rightarrow+\infty}a^x=0 ~~,~~ \lim_{x\rightarrow-\infty}a^x=+\infty ~~~~ a<1
$

$ \displaystyle
\lim_{x\rightarrow+\infty}\log_ax=+\infty ~~,~~ \lim_{x\rightarrow0^+}\log_ax=-\infty ~~~~ a>1
$

$ \displaystyle
\lim_{x\rightarrow+\infty}\log_ax=-\infty ~~,~~ \lim_{x\rightarrow0^+}\log_ax=+\infty ~~~~ a<1
$

$ \displaystyle
\lim_{x\rightarrow+\infty}\frac{x^\alpha}{e^x}=0 ~~,~~ \lim_{x\rightarrow-\infty}\frac{e^x}{\left|x\right|^\alpha}=0 ~~~~ a>1
$

$ \displaystyle
\lim_{x\rightarrow+\infty}\frac{\ln(x)}{x^\alpha}=0 ~~,~~ \lim_{x\rightarrow 0^+}\ln(x)x^\alpha=0 ~~~~ a>0
$


$ \displaystyle
\lim_{x\rightarrow0}(1+x)^{1/x}={\rm e}~~,~~
\lim_{x\rightarrow\infty}\left(1+\frac{n}{x}\right)^x={\rm e}^n
$

$ \displaystyle
\lim_{x\rightarrow\infty}\frac{x^p}{a^x}=0~~\mbox{als }|a|>1 ~~,~~
\lim_{x\rightarrow0}\frac{(1+x)^\alpha-1}{x}=\alpha ~~~ (a\in\mathbb{R})
$

$ \displaystyle
\lim_{x\rightarrow0}\left(a^{1/x}-1\right)=\ln(a)~~,~~
\lim_{x\rightarrow\infty}\sqrt[x]{x}=1
$

\subsubsection{Substitution rule}
\[
\text{given  } \lim_{x\rightarrow c}f(x)=l \text{   then   } \lim_{x\rightarrow c}g(f(x))=\lim_{y\rightarrow l}g(y) 
\]

\section{Series}
\textbf{Definition:} In mathematics, a series is, roughly speaking, a description of the operation of adding infinitely many quantities, one after the other, to a given starting quantity.

\subsection{Convergence and divergence}
Absolute Convergence: If $\sum\left|s_n\right|$ is convergent.

Conditional Convergence: If $\sum s_n$ is convergent but not absolutely convergent.

If $\sum\limits_n|u_n|$ converges, $\sum\limits_n u_n$ also converges.

If $\lim\limits_{n\rightarrow\infty}u_n\neq0$ then $\sum\limits_n u_n$ is divergent.

\subsection{Positive Series}
Positive Series: If all the terms $ s^n $ are positive.

If $u_n>0~\forall n$ then $\sum\limits_n u_n$ is convergent if 
$\sum\limits_n\ln(u_n+1)$ is convergent.

Integral Test: If $ f(n) = s_n $, continuous, positive, decreasing: $\sum s_n$ converges $ \Leftrightarrow \int_{1}^{\infty}f(x)dx $ converges.

Comparison Test: $\sum a_n$ and $\sum b_n$ where $a_k<b_k ~ (\forall k\ge m) 
\begin{cases}
\text{If } \sum b_n \text{ converges, so does } \sum a_n \\
\text{If } \sum a_n \text{ diverges, so does } \sum b_n
\end{cases}
$

Limit Comparison Test: $\sum a_n$ and $\sum b_n$ such that $ \lim_{n\rightarrow\infty} \frac{a_n}{b_n}$ exists, $\sum a_n$ converges $\Leftrightarrow$ $\sum b_n$ converges.

Ratio Test: if $\lim_{n\rightarrow \infty}\left|\frac{s_{n+1}}{s_n}\right| = \begin{cases}
<1 \text{ then it is absolutely convergent} \\
1 \text{ then no conclusion} \\
>1 \text{ or } +\infty \text{ then it diverges}
\end{cases}
$

Root Test: if  $\lim_{n\rightarrow \infty} \sqrt[n]{\left|s_n\right|} = \begin{cases}
<1 \text{ then it is absolutely convergent} \\
1 \text{ then no conclusion} \\
>1 \text{ or } +\infty \text{ then it diverges}
\end{cases}
$

\subsection{Alternating Series}
Alternating Series: $ \sum(-1)^{n+1}a_n=a_1-a_2+a_3-a_4+a_5-... $

Leibniz Test: An alternating series of which the absolute values of the terms drop
monotonously to 0 is convergent.

\subsection{Common Series}
\subsubsection{Basic Series}

\begin{tabular}{ l l }
$ \displaystyle \sum_{k=1}^n k = \frac{n(n+1)}{2} $ &
$ \displaystyle \sum_{k=1}^n (2k-1) = n^2 $ \\ [1.5em]
$ \displaystyle \sum_{k=1}^n k^2 = \frac{n(n+1)(2n+1)}{6} $ & 
$ \displaystyle \sum_{k=1}^n k^3 = \frac{n^2(n+1)^2}{4} $
\end{tabular}

\subsubsection{Harmonic Series}
\[
\sum_{n=1}^\infty \frac{1}{n^p} ~ \begin{cases}
									\text{is convergent if } p>1 \\
									\text{is divergent if } p\leq1
									\end{cases}
\]

\subsubsection{Geometric Series}
\[
\sum_{0}^{n}q^k=1+q+q^2+...+q^n= \begin{cases}
									n+1 & q=1 \\
									\frac{1-q^{k+1}}{1-q} & q\ne1
								 \end{cases}
~ \text{ then } ~
\sum_{0}^{+\infty}q^k= \begin{cases}
\frac{1}{1-q} & \left|q\right|<1 \\
+\infty & q\ge1 \\
\text{no conclusion} & q\le-1
\end{cases}
\]

\subsubsection{Mengoli Series}
\[
s_n=\sum_{k=2}^{n}\frac{1}{(k-1)k}=1-\frac{1}{n} ~~ \text{ then } ~~  \lim_{n\rightarrow\infty}s_n=1
\]

\section{Derivatives}
The derivative of a function is the ratio of the difference of function value $ f(x) $ at points $ x+\Delta x $ and $ x $ with $ \Delta x $, when $ \Delta x $ is infinitesimally small. The derivative is the function slope or slope of the tangent line at point x.

\[
f^\prime(x) = \lim_{\Delta x \rightarrow 0} \frac{ f( x + \Delta x ) - f(x) }{\Delta x}
\]

\subsection{Derivatives rules}
\begin{tabular}{ l l }
Sum rule:      & $ \displaystyle (\alpha f(x) \pm \beta g(x) )^\prime = \alpha f^\prime(x) \pm \beta g^\prime(x) $  \\
Product rule:  & $ \displaystyle (f(x) \cdot g(x) )^\prime = f^\prime(x) g(x) + f(x) g^\prime(x) $ \\
Quotient rule: & $ \displaystyle \left( \frac{f(x)}{g(x)} \right)^\prime = \frac{ f^\prime(x) g(x) - f(x) g^\prime(x) }{ g^2(x) } $ \\
Chain rule:    & $ \displaystyle f\left( g(x) \right) ^\prime = f^\prime\left( g(x) \right) \cdot g^\prime(x) $
\end{tabular}


\subsection{Second derivative test}

If $ f^\prime(x_0) = 0 $ then $ \begin{cases}
									f^{\prime\prime}(x_0) > 0 & \text{local minimum} \\
									f^{\prime\prime}(x_0) < 0 & \text{local maximum} \\
									f^{\prime\prime}(x_0) = 0 & \text{undetermined}
								\end{cases}
$

\subsection{Common derivatives}
\subsubsection{Basic Derivatives}
$ \displaystyle f(x)=\alpha ~ \Rightarrow ~ f^\prime(x)=0 $

$ \displaystyle f(x)=x ~ \Rightarrow ~ f^\prime(x)=1 $

$ \displaystyle f(x)=x^n ~ \Rightarrow ~ f^\prime(x)=n x^{n-1} $

\subsubsection{Trigonometric Derivatives}
\begin{tabular}{ l l }
$ \displaystyle f(x)=\sin(x) ~ \Rightarrow ~ f^\prime(x)=\cos(x) $ & 
$ \displaystyle f(x)=\arcsin(x) ~ \Rightarrow ~ f^\prime(x)= \frac{1}{ \sqrt{1-x^2} } $ \\ [2ex]
$ \displaystyle f(x)=\cos(x) ~ \Rightarrow ~ f^\prime(x)=-\sin(x) $ &
$ \displaystyle f(x)=\arccos(x) ~ \Rightarrow ~ f^\prime(x)= -\frac{1}{ \sqrt{1-x^2} } $ \\ [2ex]
$ \displaystyle f(x)=\tan(x) ~ \Rightarrow ~ f^\prime(x)=\sec^2(x)= \frac{1}{\cos^2(x)} $ & 
$ \displaystyle f(x)=\arctan(x) ~ \Rightarrow ~ f^\prime(x)= \frac{1}{ 1+x^2 } $ \\ [2ex]
$ \displaystyle f(x)=\sec(x) ~ \Rightarrow ~ f^\prime(x)=\sec(x)\tan(x) $ \\ [2ex]
$ \displaystyle f(x)=\cot(x) ~ \Rightarrow ~ f^\prime(x)=-\csc^2(x) $ \\ [2ex]
$ \displaystyle f(x)=\csc(x) ~ \Rightarrow ~ f^\prime(x)=-\csc(x)\cot(x) $
\end{tabular}


\subsubsection{Exponential Derivatives}
\begin{tabular}{ l l }
$ \displaystyle  f(x)=a^x ~ \Rightarrow ~ f^\prime(x)=\ln(a)a^x $ & 
$ \displaystyle  f(x)=e^x ~ \Rightarrow ~ f^\prime(x)=e^x $ \\ 
$ \displaystyle  f(x)=a^{g(x)} ~ \Rightarrow ~ f^\prime(x)=\ln(a)a^{g(x)}g^\prime(x) $ & 
$ \displaystyle  f(x)=e^{g(x)} ~ \Rightarrow ~ f^\prime(x)=e^{g(x)}g^\prime(x) $ 
\end{tabular}


\subsubsection{Logarithm Derivatives}
\begin{tabular}{ l l }
$ \displaystyle  f(x)=\log_a(x) ~ \Rightarrow ~ f^\prime(x)= \frac{1}{ \ln(a)x } $ & 
$ \displaystyle  f(x)=\ln(x) ~ \Rightarrow ~ f^\prime(x)= \frac{1}{ x } $ \\ [1.5ex] 
$ \displaystyle  f(x)=\log_a(g(x)) ~ \Rightarrow ~ f^\prime(x)= \frac{g^\prime(x)}{ \ln(a)g(x) } $ & 
$ \displaystyle  f(x)=\ln(g(x)) ~ \Rightarrow ~ f^\prime(x)= \frac{g^\prime(x)}{ g(x) } $ 
\end{tabular}


\section{Integral Calculus}
\textbf{Definition:} In mathematics, Integral calculus is a subfield of calculus in which the notion of an integral, its properties and methods of calculation are studied. It concerns accumulation of quantities and the areas under and between curves.


\section{Differential calculus}
\textbf{Definition:} In mathematics, differential calculus is a subfield of calculus concerned with the study of the rates at which quantities change.

